{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "764987f0-37e7-4c90-a208-bca92a930663",
   "metadata": {},
   "source": [
    "# Imbalance model evaluate\n",
    "## - overrepresntation the minorty label\n",
    "#### The postive example will be overpresented over the negative example. New folder will be genrated with overrepresntation of the phnotype.\n",
    "#### Data split : \n",
    "#### phno = 90%\n",
    "#### norm = 10%\n",
    "## - logistic regression of fetures calculate from peroxisome examples\n",
    "~## - change loss wight acording to the example on tenserflow website:~\n",
    "~#### https://www.tensorflow.org/tutorials/structured_data/imbalanced_data~\n",
    "## - save callbacks and best loss\n",
    "***\n",
    "\n",
    "## **- overrepresntation the minorty label**\n",
    "# 1. 10 % imbalance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a12fb20d-f5bd-48c9-a3a4-454d51239514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "#import glob\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression as CustomLogisticRegression\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.models import load_model\n",
    "os.chdir('/data/kanferg/Images/Pex_project/Transfer_learning/code')\n",
    "from utils import Taining_data_orgenizer as orgenizer \n",
    "from utils import model_builder as mb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54465f86-a163-4a07-bb60-ccf5b39c5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set/input_sc_mix'\n",
    "path_origen = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set/imbalance'\n",
    "label_A = 'norm'\n",
    "label_B = 'pheno'\n",
    "file_extention = 'png' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d22f4a-5373-4034-a354-0e6078514866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_builder = orgenizer.classification_data_orgenizer(path_input = path_input,path_origen = path_origen,label_A=label_A,label_B =label_B,\n",
    "                                                       file_extention =file_extention)\n",
    "\n",
    "path_builder.get_file_names_list()\n",
    "\n",
    "statment_a, statment_b, train_files, validate_files, test_files = path_builder.split_traning_set_and_copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70925060-f7af-4b87-a5ca-85326c5b2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(statment_a)\n",
    "print(statment_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359b0c2-0b0c-479d-9fcd-86b727dbafd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### phno = 9217 train, 1152 validation\n",
    "#### norm = 921 train 115 validation\n",
    "#### The test will be later changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a04ee7-ecdc-4d9c-a4bf-02c99ea44550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_input = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set/input_sc_mix'\n",
    "path_origen = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set'\n",
    "\n",
    "train_dir = os.path.join(path_origen, 'training_data')\n",
    "val_dir = os.path.join(path_origen, 'validation_data')\n",
    "test_dir = os.path.join(path_origen, 'test_data')\n",
    "\n",
    "'''\n",
    "batch size, epochs, steps_per_epoch_sel, validation_steps \n",
    "'''\n",
    "batch  = 30\n",
    "epoch  = 100\n",
    "step_per_epoch = int((9930)/30)\n",
    "validation_steps = int((1242)/30)\n",
    "path_model = '/data/kanferg/Images/Pex_project/Transfer_learning/models'\n",
    "# extract_size_train = 1000\n",
    "# extract_size_val = 200\n",
    "IMG_DIM=(150,150,3)\n",
    "imbalance_train = 921\n",
    "imbalance_val = 115\n",
    "\n",
    "'''\n",
    "load image files (1000 for training and 200  for validation)\n",
    "'''\n",
    "\n",
    "model_build = mb.model_builder(IMG_DIM=(150,150,3),path_training=train_dir,path_validation=val_dir,\n",
    "                 batch=batch, epoch = epoch,input_shape = (150,150,3) ,steps_per_epoch_sel= step_per_epoch,\n",
    "                 validation_steps=validation_steps,path_model = path_model,file_extention = 'png',\n",
    "                 imbalance_train = imbalance_train, imbalance_val = imbalance_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7b394-1903-43c5-a0df-62a59bb6d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_build.display_data_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bda93c-c800-4970-bfd7-8a6e05973210",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_scaled, validation_imgs_scaled,train_labels_enc,validation_labels_enc,train_imgs,validation_imgs,report = model_build.build_image__sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eab357-9555-4256-972e-d0f44ef32b23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 15))\n",
    "ax[0].imshow(train_imgs_scaled[0], cmap=plt.cm.gray)\n",
    "ax[0].title.set_text(str(train_labels_enc[0]) + ' norm')\n",
    "ax[1].imshow(train_imgs_scaled[3], cmap=plt.cm.gray)\n",
    "ax[1].title.set_text(str(train_labels_enc[3]) + ' pheno')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d06d6e-8e18-430a-9308-5436639c064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of training samples pheno: {}'.format(np.sum(train_labels_enc)))\n",
    "print('number of training samples norm: {}'.format(np.abs(np.sum(train_labels_enc-1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6089458-8ccb-4d9e-b30e-677b7d42a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_enc[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf75e53-bc7d-41e9-9429-c0b4e1ff6df1",
   "metadata": {},
   "source": [
    "# Build model on the imbalance data\n",
    "#### The drop of layer 4,and 5 got the best result on balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b243f-da71-4b76-9e34-45f7a0f3acb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_imbalance = model_build.model_cnn_transfer_learning_Augmentation_drop_layer_4and5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ae9ea-790e-4d16-9fca-23038f308031",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = '/data/kanferg/Images/Pex_project/Transfer_learning/models'\n",
    "os.chdir(path_model)\n",
    "model_imbalance.save('model_imbalance_10_percent.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41749d1-6085-4295-b929-b6642be565db",
   "metadata": {},
   "source": [
    "# 2. 20 % imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7d623a-a8bc-41e2-af14-eb67f0eef420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_input = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set/input_sc_mix'\n",
    "path_origen = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set'\n",
    "\n",
    "train_dir = os.path.join(path_origen, 'training_data')\n",
    "val_dir = os.path.join(path_origen, 'validation_data')\n",
    "test_dir = os.path.join(path_origen, 'test_data')\n",
    "\n",
    "'''\n",
    "batch size, epochs, steps_per_epoch_sel, validation_steps \n",
    "'''\n",
    "batch  = 30\n",
    "epoch  = 100\n",
    "step_per_epoch = int((8000)/30)\n",
    "validation_steps = int((2000)/30)\n",
    "path_model = '/data/kanferg/Images/Pex_project/Transfer_learning/models'\n",
    "IMG_DIM=(150,150,3)\n",
    "imbalance_train = 2000\n",
    "imbalance_val = 300\n",
    "\n",
    "'''\n",
    "load image files (1000 for training and 200  for validation)\n",
    "'''\n",
    "\n",
    "model_build = mb.model_builder(IMG_DIM=(150,150,3),path_training=train_dir,path_validation=val_dir,\n",
    "                 batch=batch, epoch = epoch,input_shape = (150,150,3) ,steps_per_epoch_sel= step_per_epoch,\n",
    "                 validation_steps=validation_steps,path_model = path_model,file_extention = 'png',\n",
    "                 imbalance_train = imbalance_train,\n",
    "                              imbalance_val = imbalance_val)\n",
    "train_imgs_scaled, validation_imgs_scaled,train_labels_enc,validation_labels_enc,train_imgs,validation_imgs,report = model_build.build_image__sets()\n",
    "print('number of training samples pheno: {}'.format(np.sum(train_labels_enc)))\n",
    "print('number of training samples norm: {}'.format(np.abs(np.sum(train_labels_enc-1))))\n",
    "model_imbalance_20percent = model_build.model_cnn_transfer_learning_Augmentation_drop_layer_4and5()\n",
    "path_model = '/data/kanferg/Images/Pex_project/Transfer_learning/models'\n",
    "os.chdir(path_model)\n",
    "model_imbalance_20percent.save('model_imbalance_20_percent.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627f4135-96c6-4f04-be4b-844b68006ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### phno = 8000 train, 2000 validation\n",
    "#### norm = 2000 train 300 validation\n",
    "#### The test will be later changed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35538b2-b8a0-4522-bcee-1daa3a4cc237",
   "metadata": {},
   "source": [
    "***\n",
    "## **- logistic regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6151f2e-3ae9-4425-989f-95fde2820e42",
   "metadata": {},
   "source": [
    "### Fetures measured from Peroxidome staining were calculated and sumarrized in the table bellow:\n",
    "/data/kanferg/Images/Pex_project/Basyein_classifcation/Tables\n",
    "- [x] merege all the tables\n",
    "- [ ] remove area outlier\n",
    "- [ ] creat train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55de55a1-cb37-4720-b5bd-46f5d0ba3f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 20/20 [00:00<00:00, 57.26it/s]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:00<00:00, 42.15it/s]\n"
     ]
    }
   ],
   "source": [
    "path_origen = '/data/kanferg/Images/Pex_project/Basyein_classifcation/Tables'\n",
    "path_norm = '/data/kanferg/Images/Pex_project/Basyein_classifcation/Tables/norm/'\n",
    "path_pheno = '/data/kanferg/Images/Pex_project/Basyein_classifcation/Tables/pheno/'\n",
    "train_dir = os.path.join(path_origen, 'training_data')\n",
    "test_dir = os.path.join(path_origen, 'test_data')\n",
    "# norm merage\n",
    "def merge_cvs(path):\n",
    "    file_names = [file for file in os.listdir(path) if file.endswith('csv')]\n",
    "    df = pd.DataFrame()\n",
    "    os.chdir(path)\n",
    "    for i in tqdm(range(len(file_names))):\n",
    "        df1 = pd.read_csv(file_names[i])\n",
    "        df = pd.concat([df, df1], ignore_index=True)\n",
    "    return df\n",
    "df_norm = merge_cvs(path_norm)\n",
    "df_pheno = merge_cvs(path_pheno)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9666fe21-d1a3-4200-baaf-5ab31c238e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(series):\n",
    "    \"\"\"Standardize a pandas series\"\"\"\n",
    "    return (series - series.mean()) / series.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac804e4-9faf-497b-9508-0a83dbd71814",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_norm, df_pheno], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f311f1e-a13a-46c5-a247-dff99a655dce",
   "metadata": {},
   "source": [
    "### Sufffle class assign and remove irelevent fetures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8329d2-433c-474e-bfd0-0d44115b1ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>area</th>\n",
       "      <th>eccentricity</th>\n",
       "      <th>euler_number</th>\n",
       "      <th>extent</th>\n",
       "      <th>feret_diameter_max</th>\n",
       "      <th>inertia_tensor-0-0</th>\n",
       "      <th>inertia_tensor-0-1</th>\n",
       "      <th>...</th>\n",
       "      <th>moments_normalized-3-3</th>\n",
       "      <th>orientation</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>perimeter_crofton</th>\n",
       "      <th>solidity</th>\n",
       "      <th>sd_intensity</th>\n",
       "      <th>skew_intensity</th>\n",
       "      <th>pixelcount</th>\n",
       "      <th>mean_int</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26359</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>3723</td>\n",
       "      <td>0.205078</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672264</td>\n",
       "      <td>79.309520</td>\n",
       "      <td>304.525279</td>\n",
       "      <td>0.509766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.038168</td>\n",
       "      <td>243.865007</td>\n",
       "      <td>233.880041</td>\n",
       "      <td>0.946125</td>\n",
       "      <td>63.785374</td>\n",
       "      <td>-0.031239</td>\n",
       "      <td>3723</td>\n",
       "      <td>287.801236</td>\n",
       "      <td>pheno_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18113</td>\n",
       "      <td>593</td>\n",
       "      <td>594</td>\n",
       "      <td>6958</td>\n",
       "      <td>0.622443</td>\n",
       "      <td>1</td>\n",
       "      <td>0.656415</td>\n",
       "      <td>117.647779</td>\n",
       "      <td>584.230305</td>\n",
       "      <td>143.403835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000465</td>\n",
       "      <td>-0.727625</td>\n",
       "      <td>340.048773</td>\n",
       "      <td>325.067970</td>\n",
       "      <td>0.954066</td>\n",
       "      <td>144.738341</td>\n",
       "      <td>0.048063</td>\n",
       "      <td>6958</td>\n",
       "      <td>470.101466</td>\n",
       "      <td>pheno_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25606</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>4918</td>\n",
       "      <td>0.936114</td>\n",
       "      <td>1</td>\n",
       "      <td>0.584224</td>\n",
       "      <td>145.784087</td>\n",
       "      <td>239.318823</td>\n",
       "      <td>-297.842399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.324171</td>\n",
       "      <td>329.391919</td>\n",
       "      <td>315.357337</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>367.928788</td>\n",
       "      <td>0.237794</td>\n",
       "      <td>4918</td>\n",
       "      <td>1179.637048</td>\n",
       "      <td>pheno_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6815</td>\n",
       "      <td>387</td>\n",
       "      <td>388</td>\n",
       "      <td>4182</td>\n",
       "      <td>0.953444</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558941</td>\n",
       "      <td>134.480482</td>\n",
       "      <td>1046.285981</td>\n",
       "      <td>-279.156429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>1.283165</td>\n",
       "      <td>315.078210</td>\n",
       "      <td>301.394392</td>\n",
       "      <td>0.943805</td>\n",
       "      <td>452.456287</td>\n",
       "      <td>1.197908</td>\n",
       "      <td>4182</td>\n",
       "      <td>718.698470</td>\n",
       "      <td>norm_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18144</td>\n",
       "      <td>624</td>\n",
       "      <td>625</td>\n",
       "      <td>9051</td>\n",
       "      <td>0.687992</td>\n",
       "      <td>1</td>\n",
       "      <td>0.708660</td>\n",
       "      <td>135.417872</td>\n",
       "      <td>679.745618</td>\n",
       "      <td>221.036954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.592154</td>\n",
       "      <td>378.190909</td>\n",
       "      <td>361.228982</td>\n",
       "      <td>0.979439</td>\n",
       "      <td>144.496973</td>\n",
       "      <td>-0.785987</td>\n",
       "      <td>9051</td>\n",
       "      <td>682.611203</td>\n",
       "      <td>pheno_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  Unnamed: 0  label  area  eccentricity  euler_number    extent  \\\n",
       "0  26359          32     33  3723      0.205078             1  0.672264   \n",
       "1  18113         593    594  6958      0.622443             1  0.656415   \n",
       "2  25606         120    121  4918      0.936114             1  0.584224   \n",
       "3   6815         387    388  4182      0.953444             1  0.558941   \n",
       "4  18144         624    625  9051      0.687992             1  0.708660   \n",
       "\n",
       "   feret_diameter_max  inertia_tensor-0-0  inertia_tensor-0-1  ...  \\\n",
       "0           79.309520          304.525279            0.509766  ...   \n",
       "1          117.647779          584.230305          143.403835  ...   \n",
       "2          145.784087          239.318823         -297.842399  ...   \n",
       "3          134.480482         1046.285981         -279.156429  ...   \n",
       "4          135.417872          679.745618          221.036954  ...   \n",
       "\n",
       "   moments_normalized-3-3  orientation   perimeter  perimeter_crofton  \\\n",
       "0               -0.000043    -0.038168  243.865007         233.880041   \n",
       "1               -0.000465    -0.727625  340.048773         325.067970   \n",
       "2                0.002390     0.324171  329.391919         315.357337   \n",
       "3                0.003249     1.283165  315.078210         301.394392   \n",
       "4               -0.000678    -0.592154  378.190909         361.228982   \n",
       "\n",
       "   solidity  sd_intensity  skew_intensity  pixelcount     mean_int   class  \n",
       "0  0.946125     63.785374       -0.031239        3723   287.801236  pheno_  \n",
       "1  0.954066    144.738341        0.048063        6958   470.101466  pheno_  \n",
       "2  0.969446    367.928788        0.237794        4918  1179.637048  pheno_  \n",
       "3  0.943805    452.456287        1.197908        4182   718.698470   norm_  \n",
       "4  0.979439    144.496973       -0.785987        9051   682.611203  pheno_  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df).reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18e2bb4-aea2-4d04-859c-985d13b86b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class assigne\n",
    "class_name =  df['class'].values\n",
    "le = preprocessing.LabelEncoder()\n",
    "class_name_encoded=le.fit_transform(class_name).tolist()\n",
    "class_name_encoded[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775434d-bec4-49f6-9db3-56a4a42061ba",
   "metadata": {},
   "source": [
    "pehno = 1\n",
    "norm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "698cb1be-ba07-457a-9614-2069b04db83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_summary_id = df\n",
    "table_dict={'id':table_summary_id.index.to_list(),\n",
    "            'Ecc_std':standardize(table_summary_id.eccentricity),\n",
    "            'ex_std':standardize(table_summary_id.extent),\n",
    "            'orien_std':standardize(table_summary_id.orientation),\n",
    "            'solid_std':standardize(table_summary_id.solidity),\n",
    "            'feret_diameter_max':standardize(np.log(table_summary_id.feret_diameter_max).values),\n",
    "            'peri_log':standardize(np.log(table_summary_id.perimeter).values),\n",
    "            'area_log':standardize(np.log(table_summary_id.area).values),\n",
    "            'class_label':class_name_encoded}\n",
    "table = pd.DataFrame(table_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "983eb511-1d3c-4e42-bb1f-cacd6cf83997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples pheno: 16079\n",
      "number of training samples norm: 12162\n"
     ]
    }
   ],
   "source": [
    "print('number of training samples pheno: {}'.format(class_name_encoded.count(1)))\n",
    "print('number of training samples norm: {}'.format(class_name_encoded.count(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c77a7907-edcb-4342-8d49-582dc45ec99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda/envs/py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ecc_std</th>\n",
       "      <th>ex_std</th>\n",
       "      <th>orien_std</th>\n",
       "      <th>solid_std</th>\n",
       "      <th>feret_diameter_max</th>\n",
       "      <th>peri_log</th>\n",
       "      <th>area_log</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.952063</td>\n",
       "      <td>-0.238723</td>\n",
       "      <td>-0.072097</td>\n",
       "      <td>-0.318536</td>\n",
       "      <td>-0.077132</td>\n",
       "      <td>0.231910</td>\n",
       "      <td>0.274663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.478012</td>\n",
       "      <td>-0.409997</td>\n",
       "      <td>-0.817973</td>\n",
       "      <td>-0.148374</td>\n",
       "      <td>0.927960</td>\n",
       "      <td>1.091977</td>\n",
       "      <td>1.120737</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.381363</td>\n",
       "      <td>-1.190122</td>\n",
       "      <td>0.319891</td>\n",
       "      <td>0.181205</td>\n",
       "      <td>1.474506</td>\n",
       "      <td>1.009609</td>\n",
       "      <td>0.651282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.484088</td>\n",
       "      <td>-1.463339</td>\n",
       "      <td>1.357358</td>\n",
       "      <td>-0.368240</td>\n",
       "      <td>1.268797</td>\n",
       "      <td>0.894681</td>\n",
       "      <td>0.431955</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.089456</td>\n",
       "      <td>0.154580</td>\n",
       "      <td>-0.671415</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>1.286502</td>\n",
       "      <td>1.366987</td>\n",
       "      <td>1.476536</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Ecc_std    ex_std  orien_std  solid_std  feret_diameter_max  peri_log  \\\n",
       "0 -2.952063 -0.238723  -0.072097  -0.318536           -0.077132  0.231910   \n",
       "1 -0.478012 -0.409997  -0.817973  -0.148374            0.927960  1.091977   \n",
       "2  1.381363 -1.190122   0.319891   0.181205            1.474506  1.009609   \n",
       "3  1.484088 -1.463339   1.357358  -0.368240            1.268797  0.894681   \n",
       "4 -0.089456  0.154580  -0.671415   0.395346            1.286502  1.366987   \n",
       "\n",
       "   area_log  class_label  \n",
       "0  0.274663            1  \n",
       "1  1.120737            1  \n",
       "2  0.651282            1  \n",
       "3  0.431955            0  \n",
       "4  1.476536            1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = table.drop('id',1)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20559c20-beff-454d-a49c-a1ad3595df29",
   "metadata": {},
   "source": [
    "- [ ] merege all the tables\n",
    "- [x] remove area outlier\n",
    "- [ ] creat train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e853dc1-3021-4269-95e3-ab6260e9fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(table)  # What data to use\n",
    "  + aes(x=\"area_log\")  # What variable to use\n",
    "  + geom_density()  # Geometric object to use for drawing\n",
    "  + theme(axis_title_x = element_text(size = 12))\n",
    "  + theme(axis_title_y = element_text(size = 12))\n",
    "  + theme(axis_text = element_text(size=12))\n",
    "  + theme(axis_line = element_line(colour = \"black\",size=1), panel_border = element_blank(),panel_background = element_blank())\n",
    "  + labs(title=\"\", x=\"log area\", y=\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d41c47-b1fa-45de-9f5e-47782c831c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outlires beased on zscore\n",
    "table = table.loc[table.area_log > -2.5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cab328-aa63-4543-a1a3-801b259d30c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(table)  # What data to use\n",
    "  + aes(x=\"area_log\")  # What variable to use\n",
    "  + geom_density()  # Geometric object to use for drawing\n",
    "  + theme(axis_title_x = element_text(size = 12))\n",
    "  + theme(axis_title_y = element_text(size = 12))\n",
    "  + theme(axis_text = element_text(size=12))\n",
    "  + theme(axis_line = element_line(colour = \"black\",size=1), panel_border = element_blank(),panel_background = element_blank())\n",
    "  + labs(title=\"\", x=\"log area\", y=\"count\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0df424-4518-4fe7-9e2e-b5516f1684da",
   "metadata": {},
   "source": [
    "- [ ] merege all the tables\n",
    "- [ ] remove area outlier\n",
    "- [x] creat train and test set and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09b009-7502-48cc-841e-405a7b897890",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(train_dir) if not os.path.isdir(train_dir) else None\n",
    "os.mkdir(test_dir) if not os.path.isdir(test_dir) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69426f57-a6e9-4b38-b64f-919dcef05c8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    15626\n",
       "0    11922\n",
       "Name: class_label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " table['class_label'].value_counts(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17772907-7e17-4789-8b7d-bb927e4bc9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save training and test:\n",
    "table_train = table.loc[:24999,:]\n",
    "table_test = table.loc[25000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065a0a92-5797-4021-8375-4e8d5e315298",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = table_train.loc[:,table_train.columns != 'class_label']\n",
    "y_train = table_train.iloc[:,-1]\n",
    "x_test = table_test.loc[:,table_train.columns != 'class_label']\n",
    "y_test = table_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48905fa7-a586-4292-95f5-2b7d97bfa0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=10000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = CustomLogisticRegression(solver='lbfgs',class_weight='balanced', max_iter=10000)\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7eec3e98-ccbc-4a24-a94d-b3b1cdc0365a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5236583042235631\n"
     ]
    }
   ],
   "source": [
    "pred = lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed5a163f-c265-4520-b008-49a4fa757000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "path_model = '/data/kanferg/Images/Pex_project/Transfer_learning/models'\n",
    "os.chdir(path_model)\n",
    "os.getcwd()\n",
    "with open('lr.pkl','wb') as buff:\n",
    "    pickle.dump({'model':lr},buff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97bd403e-8420-4935-be49-99da81d414c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5236583042235631\n"
     ]
    }
   ],
   "source": [
    "pred = lr.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "584902b8-0d73-44f5-aad2-5a3ead20c98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb285b-4265-456a-854c-46ca91896ccf",
   "metadata": {},
   "source": [
    "~## - change loss wight acording to tenserflow example~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad2cdb9-a141-4e40-8e9f-63ce1b1887b8",
   "metadata": {},
   "source": [
    "## - save callbacks and best loss\n",
    "Change the modele builder function for including stop when loss is not getting better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cb165b-1ea9-40e6-ab3d-c505600e5149",
   "metadata": {},
   "source": [
    "- [x] 10 %\n",
    "- [x] 20 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8a6e21-7216-4942-b969-2b45f51416b9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training samples norm: 9050\n",
      "number of training samples pheno: 9009\n",
      "run training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 9930/9930 [02:59<00:00, 55.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run valadtion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 1242/1242 [00:22<00:00, 54.29it/s]\n",
      "2022-05-24 14:29:09.798741: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-24 14:29:10.451608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14627 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:91:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/gsfs10/users/kanferg/Images/Pex_project/Transfer_learning/code/utils/model_builder.py:402: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-24 14:29:16.407011: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 7605\n",
      "2022-05-24 14:29:16.707034: W tensorflow/stream_executor/gpu/asm_compiler.cc:80] Couldn't get ptxas version string: INTERNAL: Running ptxas --version returned 32512\n",
      "2022-05-24 14:29:16.814028: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] INTERNAL: ptxas exited with non-zero error code 32512, output: \n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/331 [==============================] - ETA: 0s - loss: 0.0832 - accuracy: 0.9676\n",
      "Epoch 00001: val_loss improved from inf to 0.00165, saving model to /data/kanferg/Images/Pex_project/Transfer_learning/models/percent10_chp/cnn_transfer_learning_Augmentation_drop_layer_4and5.h5\n",
      "331/331 [==============================] - 67s 183ms/step - loss: 0.0832 - accuracy: 0.9676 - val_loss: 0.0016 - val_accuracy: 0.9984\n",
      "Epoch 2/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9953\n",
      "Epoch 00002: val_loss improved from 0.00165 to 0.00065, saving model to /data/kanferg/Images/Pex_project/Transfer_learning/models/percent10_chp/cnn_transfer_learning_Augmentation_drop_layer_4and5.h5\n",
      "331/331 [==============================] - 60s 183ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 6.5008e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0171 - accuracy: 0.9958\n",
      "Epoch 00003: val_loss did not improve from 0.00065\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0171 - accuracy: 0.9958 - val_loss: 0.0087 - val_accuracy: 0.9984\n",
      "Epoch 4/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9954\n",
      "Epoch 00004: val_loss did not improve from 0.00065\n",
      "331/331 [==============================] - 61s 183ms/step - loss: 0.0180 - accuracy: 0.9954 - val_loss: 0.0010 - val_accuracy: 0.9992\n",
      "Epoch 5/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9965\n",
      "Epoch 00005: val_loss did not improve from 0.00065\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.0085 - val_accuracy: 0.9984\n",
      "Epoch 6/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9975\n",
      "Epoch 00006: val_loss did not improve from 0.00065\n",
      "331/331 [==============================] - 60s 181ms/step - loss: 0.0140 - accuracy: 0.9975 - val_loss: 6.9311e-04 - val_accuracy: 0.9992\n",
      "Epoch 7/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9966\n",
      "Epoch 00007: val_loss did not improve from 0.00065\n",
      "331/331 [==============================] - 60s 183ms/step - loss: 0.0163 - accuracy: 0.9966 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 8/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9963\n",
      "Epoch 00008: val_loss improved from 0.00065 to 0.00053, saving model to /data/kanferg/Images/Pex_project/Transfer_learning/models/percent10_chp/cnn_transfer_learning_Augmentation_drop_layer_4and5.h5\n",
      "331/331 [==============================] - 61s 183ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 5.2712e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9962\n",
      "Epoch 00009: val_loss did not improve from 0.00053\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.0015 - val_accuracy: 0.9992\n",
      "Epoch 10/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9977\n",
      "Epoch 00010: val_loss did not improve from 0.00053\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 0.0015 - val_accuracy: 0.9992\n",
      "Epoch 11/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9973\n",
      "Epoch 00011: val_loss did not improve from 0.00053\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0150 - accuracy: 0.9973 - val_loss: 0.0020 - val_accuracy: 0.9992\n",
      "Epoch 12/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0142 - accuracy: 0.9969\n",
      "Epoch 00012: val_loss did not improve from 0.00053\n",
      "331/331 [==============================] - 60s 183ms/step - loss: 0.0142 - accuracy: 0.9969 - val_loss: 0.0015 - val_accuracy: 0.9992\n",
      "Epoch 13/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9976\n",
      "Epoch 00013: val_loss did not improve from 0.00053\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0163 - accuracy: 0.9976 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "Epoch 14/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9965\n",
      "Epoch 00014: val_loss did not improve from 0.00053\n",
      "331/331 [==============================] - 60s 181ms/step - loss: 0.0140 - accuracy: 0.9965 - val_loss: 0.0018 - val_accuracy: 0.9992\n",
      "Epoch 15/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9968\n",
      "Epoch 00015: val_loss improved from 0.00053 to 0.00022, saving model to /data/kanferg/Images/Pex_project/Transfer_learning/models/percent10_chp/cnn_transfer_learning_Augmentation_drop_layer_4and5.h5\n",
      "331/331 [==============================] - 61s 183ms/step - loss: 0.0151 - accuracy: 0.9968 - val_loss: 2.2137e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9975\n",
      "Epoch 00016: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0219 - accuracy: 0.9975 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "Epoch 17/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9973\n",
      "Epoch 00017: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0153 - accuracy: 0.9973 - val_loss: 0.0081 - val_accuracy: 0.9984\n",
      "Epoch 18/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9969\n",
      "Epoch 00018: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 181ms/step - loss: 0.0148 - accuracy: 0.9969 - val_loss: 0.0026 - val_accuracy: 0.9984\n",
      "Epoch 19/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9966\n",
      "Epoch 00019: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0184 - accuracy: 0.9966 - val_loss: 0.0049 - val_accuracy: 0.9984\n",
      "Epoch 20/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0134 - accuracy: 0.9972\n",
      "Epoch 00020: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 181ms/step - loss: 0.0134 - accuracy: 0.9972 - val_loss: 0.0011 - val_accuracy: 0.9992\n",
      "Epoch 21/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9965\n",
      "Epoch 00021: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 61s 183ms/step - loss: 0.0288 - accuracy: 0.9965 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "Epoch 22/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9970\n",
      "Epoch 00022: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 61s 183ms/step - loss: 0.0152 - accuracy: 0.9970 - val_loss: 0.0128 - val_accuracy: 0.9967\n",
      "Epoch 23/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9972\n",
      "Epoch 00023: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 61s 184ms/step - loss: 0.0166 - accuracy: 0.9972 - val_loss: 6.3888e-04 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9972\n",
      "Epoch 00024: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0165 - accuracy: 0.9972 - val_loss: 0.0105 - val_accuracy: 0.9984\n",
      "Epoch 25/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0157 - accuracy: 0.9975\n",
      "Epoch 00025: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 61s 183ms/step - loss: 0.0157 - accuracy: 0.9975 - val_loss: 5.6165e-04 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9967\n",
      "Epoch 00026: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0145 - accuracy: 0.9967 - val_loss: 4.4625e-04 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9973\n",
      "Epoch 00027: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0194 - accuracy: 0.9973 - val_loss: 0.2598 - val_accuracy: 0.9984\n",
      "Epoch 28/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0259 - accuracy: 0.9968\n",
      "Epoch 00028: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0259 - accuracy: 0.9968 - val_loss: 0.0080 - val_accuracy: 0.9984\n",
      "Epoch 29/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0309 - accuracy: 0.9958\n",
      "Epoch 00029: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0309 - accuracy: 0.9958 - val_loss: 0.0612 - val_accuracy: 0.9951\n",
      "Epoch 30/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9974\n",
      "Epoch 00030: val_loss did not improve from 0.00022\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0272 - accuracy: 0.9974 - val_loss: 0.0099 - val_accuracy: 0.9984\n",
      "Epoch 31/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0311 - accuracy: 0.9966\n",
      "Epoch 00031: val_loss improved from 0.00022 to 0.00020, saving model to /data/kanferg/Images/Pex_project/Transfer_learning/models/percent10_chp/cnn_transfer_learning_Augmentation_drop_layer_4and5.h5\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0311 - accuracy: 0.9966 - val_loss: 2.0266e-04 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9970\n",
      "Epoch 00032: val_loss did not improve from 0.00020\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0151 - accuracy: 0.9970 - val_loss: 0.0081 - val_accuracy: 0.9992\n",
      "Epoch 33/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9967\n",
      "Epoch 00033: val_loss did not improve from 0.00020\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0206 - accuracy: 0.9967 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
      "Epoch 34/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9960\n",
      "Epoch 00034: val_loss did not improve from 0.00020\n",
      "331/331 [==============================] - 60s 181ms/step - loss: 0.0199 - accuracy: 0.9960 - val_loss: 0.5776 - val_accuracy: 0.9984\n",
      "Epoch 35/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0459 - accuracy: 0.9965\n",
      "Epoch 00035: val_loss did not improve from 0.00020\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0459 - accuracy: 0.9965 - val_loss: 0.0221 - val_accuracy: 0.9984\n",
      "Epoch 36/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9964\n",
      "Epoch 00036: val_loss did not improve from 0.00020\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0337 - accuracy: 0.9964 - val_loss: 0.0170 - val_accuracy: 0.9984\n",
      "Epoch 37/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9969\n",
      "Epoch 00037: val_loss improved from 0.00020 to 0.00010, saving model to /data/kanferg/Images/Pex_project/Transfer_learning/models/percent10_chp/cnn_transfer_learning_Augmentation_drop_layer_4and5.h5\n",
      "331/331 [==============================] - 61s 183ms/step - loss: 0.0130 - accuracy: 0.9969 - val_loss: 9.8094e-05 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9968\n",
      "Epoch 00038: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 181ms/step - loss: 0.0235 - accuracy: 0.9968 - val_loss: 0.0018 - val_accuracy: 0.9984\n",
      "Epoch 39/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9965\n",
      "Epoch 00039: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0393 - accuracy: 0.9965 - val_loss: 7.7414e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9965\n",
      "Epoch 00040: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0202 - accuracy: 0.9965 - val_loss: 0.0173 - val_accuracy: 0.9984\n",
      "Epoch 41/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9968\n",
      "Epoch 00041: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0204 - accuracy: 0.9968 - val_loss: 0.0169 - val_accuracy: 0.9984\n",
      "Epoch 42/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9965\n",
      "Epoch 00042: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0218 - accuracy: 0.9965 - val_loss: 0.0068 - val_accuracy: 0.9984\n",
      "Epoch 43/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9971\n",
      "Epoch 00043: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0227 - accuracy: 0.9971 - val_loss: 0.0111 - val_accuracy: 0.9984\n",
      "Epoch 44/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9968\n",
      "Epoch 00044: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0225 - accuracy: 0.9968 - val_loss: 0.0927 - val_accuracy: 0.9984\n",
      "Epoch 45/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9970\n",
      "Epoch 00045: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0411 - accuracy: 0.9970 - val_loss: 0.0187 - val_accuracy: 0.9984\n",
      "Epoch 46/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9967\n",
      "Epoch 00046: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0230 - accuracy: 0.9967 - val_loss: 0.0108 - val_accuracy: 0.9992\n",
      "Epoch 47/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9965\n",
      "Epoch 00047: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0824 - accuracy: 0.9965 - val_loss: 0.0029 - val_accuracy: 0.9992\n",
      "Epoch 48/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0333 - accuracy: 0.9975\n",
      "Epoch 00048: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0333 - accuracy: 0.9975 - val_loss: 0.0448 - val_accuracy: 0.9984\n",
      "Epoch 49/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9962\n",
      "Epoch 00049: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 183ms/step - loss: 0.0276 - accuracy: 0.9962 - val_loss: 0.0132 - val_accuracy: 0.9992\n",
      "Epoch 50/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.2184 - accuracy: 0.9966\n",
      "Epoch 00050: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.2184 - accuracy: 0.9966 - val_loss: 9.1460e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9968\n",
      "Epoch 00051: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 181ms/step - loss: 0.0539 - accuracy: 0.9968 - val_loss: 0.0091 - val_accuracy: 0.9992\n",
      "Epoch 52/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9966\n",
      "Epoch 00052: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0255 - accuracy: 0.9966 - val_loss: 0.0013 - val_accuracy: 0.9992\n",
      "Epoch 53/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9971\n",
      "Epoch 00053: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0223 - accuracy: 0.9971 - val_loss: 0.0151 - val_accuracy: 0.9984\n",
      "Epoch 54/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.9968\n",
      "Epoch 00054: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0267 - accuracy: 0.9968 - val_loss: 1.1339 - val_accuracy: 0.9984\n",
      "Epoch 55/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0316 - accuracy: 0.9960\n",
      "Epoch 00055: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0316 - accuracy: 0.9960 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "Epoch 56/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9965\n",
      "Epoch 00056: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0220 - accuracy: 0.9965 - val_loss: 3.5930e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "331/331 [==============================] - ETA: 0s - loss: 0.0216 - accuracy: 0.9957\n",
      "Epoch 00057: val_loss did not improve from 0.00010\n",
      "331/331 [==============================] - 60s 182ms/step - loss: 0.0216 - accuracy: 0.9957 - val_loss: 0.0977 - val_accuracy: 0.9984\n",
      "Epoch 00057: early stopping\n",
      "number of training samples norm: 9050\n",
      "number of training samples pheno: 9009\n",
      "run training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 11009/11009 [03:47<00:00, 48.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run valadtion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 1427/1427 [00:28<00:00, 50.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9536WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 66 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01448, saving model to /data/kanferg/Images/Pex_project/Transfer_learning/models/percent20_chp/cnn_transfer_learning_Augmentation_drop_layer_4and5.h5\n",
      "266/266 [==============================] - 57s 208ms/step - loss: 0.1188 - accuracy: 0.9536 - val_loss: 0.0145 - val_accuracy: 0.9965\n",
      "Epoch 2/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9905WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0338 - accuracy: 0.9905\n",
      "Epoch 3/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9921WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0277 - accuracy: 0.9921\n",
      "Epoch 4/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9934WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0246 - accuracy: 0.9934\n",
      "Epoch 5/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9926WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0250 - accuracy: 0.9926\n",
      "Epoch 6/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9955WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0180 - accuracy: 0.9955\n",
      "Epoch 7/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9944WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 179ms/step - loss: 0.0237 - accuracy: 0.9944\n",
      "Epoch 8/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9952WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 179ms/step - loss: 0.0232 - accuracy: 0.9952\n",
      "Epoch 9/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9956WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0175 - accuracy: 0.9956\n",
      "Epoch 10/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9947WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 179ms/step - loss: 0.0218 - accuracy: 0.9947\n",
      "Epoch 11/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9949WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0187 - accuracy: 0.9949\n",
      "Epoch 12/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9949WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 181ms/step - loss: 0.0179 - accuracy: 0.9949\n",
      "Epoch 13/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0182 - accuracy: 0.9956WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 181ms/step - loss: 0.0182 - accuracy: 0.9956\n",
      "Epoch 14/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0195 - accuracy: 0.9951WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0195 - accuracy: 0.9951\n",
      "Epoch 15/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9964WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0154 - accuracy: 0.9964\n",
      "Epoch 16/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9961WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 181ms/step - loss: 0.0204 - accuracy: 0.9961\n",
      "Epoch 17/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9956WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 179ms/step - loss: 0.0186 - accuracy: 0.9956\n",
      "Epoch 18/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9959WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 181ms/step - loss: 0.0177 - accuracy: 0.9959\n",
      "Epoch 19/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9955WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0210 - accuracy: 0.9955\n",
      "Epoch 20/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9945WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0235 - accuracy: 0.9945\n",
      "Epoch 21/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0164 - accuracy: 0.9964WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0164 - accuracy: 0.9964\n",
      "Epoch 22/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9942WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0221 - accuracy: 0.9942\n",
      "Epoch 23/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9954WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0170 - accuracy: 0.9954\n",
      "Epoch 24/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0370 - accuracy: 0.9945WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 179ms/step - loss: 0.0370 - accuracy: 0.9945\n",
      "Epoch 25/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9954WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 181ms/step - loss: 0.0236 - accuracy: 0.9954\n",
      "Epoch 26/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9954WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 179ms/step - loss: 0.0280 - accuracy: 0.9954\n",
      "Epoch 27/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9956WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0383 - accuracy: 0.9956\n",
      "Epoch 28/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0670 - accuracy: 0.9952WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 47s 178ms/step - loss: 0.0670 - accuracy: 0.9952\n",
      "Epoch 29/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0410 - accuracy: 0.9951WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 179ms/step - loss: 0.0410 - accuracy: 0.9951\n",
      "Epoch 30/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0269 - accuracy: 0.9946WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0269 - accuracy: 0.9946\n",
      "Epoch 31/100\n",
      "266/266 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9939WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "266/266 [==============================] - 48s 180ms/step - loss: 0.0221 - accuracy: 0.9939\n",
      "Epoch 32/100\n",
      "137/266 [==============>...............] - ETA: 23s - loss: 0.0290 - accuracy: 0.9963"
     ]
    }
   ],
   "source": [
    "path_input = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set/input_sc_mix'\n",
    "path_origen = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set'\n",
    "\n",
    "train_dir = os.path.join(path_origen, 'training_data')\n",
    "val_dir = os.path.join(path_origen, 'validation_data')\n",
    "test_dir = os.path.join(path_origen, 'test_data')\n",
    "\n",
    "'''\n",
    "batch size, epochs, steps_per_epoch_sel, validation_steps \n",
    "'''\n",
    "batch  = 30\n",
    "epoch  = 100\n",
    "step_per_epoch = int((9930)/30)\n",
    "validation_steps = int((1242)/30)\n",
    "path_model = '/data/kanferg/Images/Pex_project/Transfer_learning/models/percent10_chp'\n",
    "# extract_size_train = 1000\n",
    "# extract_size_val = 200\n",
    "IMG_DIM=(150,150,3)\n",
    "imbalance_train = 921\n",
    "imbalance_val = 115\n",
    "add_check_point = True\n",
    "\n",
    "'''\n",
    "load image files (1000 for training and 200  for validation)\n",
    "'''\n",
    "\n",
    "model_build = mb.model_builder(IMG_DIM=(150,150,3),path_training=train_dir,path_validation=val_dir,\n",
    "                 batch=batch, epoch = epoch,input_shape = (150,150,3) ,steps_per_epoch_sel= step_per_epoch,\n",
    "                 validation_steps=validation_steps,path_model = path_model,file_extention = 'png',\n",
    "                 imbalance_train = imbalance_train,\n",
    "                    imbalance_val = imbalance_val, add_check_point = add_check_point)\n",
    "model_build.display_data_distribution()\n",
    "train_imgs_scaled, validation_imgs_scaled,train_labels_enc,validation_labels_enc,train_imgs,validation_imgs,report = model_build.build_image__sets()\n",
    "model_imbalance = model_build.model_cnn_transfer_learning_Augmentation_drop_layer_4and5()\n",
    "\n",
    "\n",
    "######################################################################################\n",
    "\n",
    "path_input = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set/input_sc_mix'\n",
    "path_origen = '/data/kanferg/Images/Pex_project/SIngle_cell_images_training_set'\n",
    "\n",
    "train_dir = os.path.join(path_origen, 'training_data')\n",
    "val_dir = os.path.join(path_origen, 'validation_data')\n",
    "test_dir = os.path.join(path_origen, 'test_data')\n",
    "\n",
    "'''\n",
    "batch size, epochs, steps_per_epoch_sel, validation_steps \n",
    "'''\n",
    "batch  = 30\n",
    "epoch  = 100\n",
    "step_per_epoch = int((8000)/30)\n",
    "validation_steps = int((2000)/30)\n",
    "path_model = '/data/kanferg/Images/Pex_project/Transfer_learning/models/percent20_chp'\n",
    "IMG_DIM=(150,150,3)\n",
    "imbalance_train = 2000\n",
    "imbalance_val = 300\n",
    "add_check_point = True\n",
    "\n",
    "\n",
    "'''\n",
    "load image files (1000 for training and 200  for validation)\n",
    "'''\n",
    "\n",
    "model_build = mb.model_builder(IMG_DIM=(150,150,3),path_training=train_dir,path_validation=val_dir,\n",
    "                 batch=batch, epoch = epoch,input_shape = (150,150,3) ,steps_per_epoch_sel= step_per_epoch,\n",
    "                 validation_steps=validation_steps,path_model = path_model,file_extention = 'png',\n",
    "                 imbalance_train = imbalance_train,\n",
    "                    imbalance_val = imbalance_val, add_check_point = add_check_point)\n",
    "model_build.display_data_distribution()\n",
    "train_imgs_scaled, validation_imgs_scaled,train_labels_enc,validation_labels_enc,train_imgs,validation_imgs,report = model_build.build_image__sets()\n",
    "model_imbalance = model_build.model_cnn_transfer_learning_Augmentation_drop_layer_4and5()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461ec4df-76dd-4316-bced-411ceff3d26c",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "### Evaluate accuarcy and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00799fbb-0196-48a9-a922-6fe26809b897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-28 10:06:37.497920: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-28 10:06:38.930582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14627 MB memory:  -> device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0000:13:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "path_model = '/data/kanferg/Images/Pex_project/Transfer_learning/models/imbalance/'\n",
    "os.chdir(path_model)\n",
    "cnn_basic = load_model('cnn_transfer_learning_Augmentation_drop_layer_4and5.h5')\n",
    "cnn_10p = load_model('cnn_transfer_learning_Augmentation_drop_layer_4and5_10p.h5')\n",
    "cnn_20p = load_model('cnn_transfer_learning_Augmentation_drop_layer_4and5_20p.h5')\n",
    "cnn_10p_ch = load_model('cnn_transfer_learning_Augmentation_drop_layer_4and5_10p_cp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e29996-d818-4807-a5de-a140158945d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_basic\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "t = f.suptitle(cnn_basic, fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epochs = self.epoch\n",
    "epoch_list = list(range(1, epochs + 1))\n",
    "ax1.plot(epoch_list, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epoch_list, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(np.arange(0, epochs + 1, 5))\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epoch_list, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epoch_list, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(np.arange(0, epochs + 1, 5))\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d691aec-232e-4e33-92ee-5a7d562f9a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(cnn_basic.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b3793c-619d-4968-b63d-9c7e0e6be5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python/3.7",
   "language": "python",
   "name": "py3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
